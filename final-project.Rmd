---
title: "Final Project"
author: "Riley Maher"
date: "3/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm)
library(stopwords)
library(tokenizers)
library(dplyr)
library(tidytext)
library(sentimentr)
library(gmodels)
library(C50)
library("caret")
```

```{r}
# memory.size() ### Checking your memory size
# memory.limit() ## Checking the set limit
# memory.limit(size=500000)
```


## Loading Data
```{r}
# News Train
news_train <- read.csv('train.csv')
news_train$id <- NULL

news_test <- read.csv('test.csv')
news_test$id <- NULL

news_test_result <- read.csv('submit.csv')

head(news_train)
```
```{r}
news_test$fake <- as.factor(news_test_result$label) #changed to factor in order to be used in confussion Matrix
```

## Data Preperation and Cleaning

### Train Data
```{r cache = TRUE}
# Cleaning article titles
news_train$cleaned_title <- tolower(news_train$title)
news_train$cleaned_title <- removePunctuation(news_train$cleaned_title)
news_train$cleaned_title <- stripWhitespace(news_train$cleaned_title)

news_train$title_character_length <- lapply(news_train$cleaned_title, nchar)#Creates variable of length of title
news_train$cleaned_title <- tokenize_words(news_train$cleaned_title, stopwords = stopwords::stopwords("en"))
news_train$cleaned_title <- lapply(news_train$cleaned_title, tokenize_word_stems)
news_train$title_word_length <- lapply(news_train$cleaned_title, length)
```


```{r cache = TRUE}
# Cleaning article text
news_train$cleaned_text <- tolower(news_train$text)
news_train$cleaned_text <- removePunctuation(news_train$cleaned_text)
news_train$cleaned_text <- stripWhitespace(news_train$cleaned_text)

# Returns emotional sentiment of article with numeric score
# news_train$text_sentiment <- sentiment(get_sentences(paste(news_train$cleaned_text, sep='', collapse=NULL)))$sentiment   
news_train$text_character_length <- lapply(news_train$cleaned_text, nchar)
news_train$cleaned_text <- tokenize_words(news_train$cleaned_text, stopwords = stopwords::stopwords("en"))
news_train$cleaned_text <- lapply(news_train$cleaned_text, tokenize_word_stems)
news_train$text_word_length <- lapply(news_train$cleaned_text, length)
```

```{r}
names(news_train)[names(news_train)== "label"] <- "fake" #renaming dependent variable for readability purposes
```

### Test Data
```{r cache = TRUE}
# Cleaning article titles
news_test$cleaned_title <- tolower(news_test$title)
news_test$cleaned_title <- removePunctuation(news_test$cleaned_title)
news_test$cleaned_title <- stripWhitespace(news_test$cleaned_title)

news_test$title_character_length <- lapply(news_test$cleaned_title, nchar)#Creates varible of length of title
news_test$cleaned_title <- tokenize_words(news_test$cleaned_title, stopwords = stopwords::stopwords("en"))
news_test$cleaned_title <- lapply(news_test$cleaned_title, tokenize_word_stems)
news_test$title_word_length <- lapply(news_test$cleaned_title, length)
```


```{r cache = TRUE}
# Cleaning article text
news_test$cleaned_text <- tolower(news_test$text)
news_test$cleaned_text <- removePunctuation(news_test$cleaned_text)
news_test$cleaned_text <- stripWhitespace(news_test$cleaned_text)

# Returns emotional sentiment of article with numeric score
# news_test$text_sentiment <- sentiment(get_sentences(paste(news_test$cleaned_text, sep='', collapse=NULL)))$sentiment 
news_test$text_character_length <- lapply(news_test$cleaned_text, nchar)
news_test$cleaned_text <- tokenize_words(news_test$cleaned_text, stopwords = stopwords::stopwords("en"))
news_test$cleaned_text <- lapply(news_test$cleaned_text, tokenize_word_stems)
news_test$text_word_length <- lapply(news_test$cleaned_text, length)
```

```{r cache = TRUE}
# Adjusting structure types for usability 
news_train$title_character_length <- as.numeric(news_train$title_character_length)
news_train$text_character_length <- as.numeric(news_train$text_character_length)
news_train$title_word_length <- as.numeric(news_train$title_word_length)
news_train$text_word_length <- as.numeric(news_train$text_word_length)

news_test$title_character_length <- as.numeric(news_test$title_character_length)
news_test$text_character_length <- as.numeric(news_test$text_character_length)
news_test$title_word_length <- as.numeric(news_test$title_word_length)
news_test$text_word_length <- as.numeric(news_test$text_word_length)

```

## Summary of Varibles
The Dependent Variable we are hoping to predict is whether or not an article is "fake" news, this is a binomial variable.

The independent variables we are using to predict fake news are: text_character_length (length of the article in characters), text_word_length (length of article in words), title_character_length (length of title in characters), title_word_length (length of title in words), sentiment (ADD EXPLINATION OF SENTIMENT)

```{r}
head(news_train)
```

```{r}
# View(news_train)
```

# Potential Things to Add

## Nice to Haves

-Parts of Speech Count

## Linear Regression

### Model Design
```{r}
FakeLinear <- lm(fake ~ text_character_length + text_word_length + title_character_length + title_word_length, data = news_train )
summary(FakeLinear)
#Significant factors: text_character_length, text_word_length, title_character_length, title_word_length
```
```{r}
FakeLinear <- lm(fake ~ text_character_length + text_word_length + title_character_length + title_word_length + (text_character_length*text_word_length) + (title_character_length*title_word_length), data = news_train )
summary(FakeLinear)
#Significant factors: text_character_length, text_word_length, title_character_length, title_word_length, title_character_length*title_word_length
```
```{r}
FakeLinear <- lm(fake ~ text_character_length + text_word_length + title_character_length + title_word_length + (title_character_length*title_word_length) + I(text_character_length ^2) + I(title_character_length ^2) +I(text_word_length ^2) +I(title_word_length ^2), data = news_train)
summary(FakeLinear)
#Significant factors: text_character_length, text_word_length, title_character_length, title_word_length, title_character_length*title_word_length, text_character_length^2, text_word_length^2, title_character_length^2, title_word_length^2
```
WILL ADD ANALYSIS AFTER ALL FACTORS AVAIBLE (i.e. sentiment)
### Model Testing
```{r}
LinearPredict <- predict(FakeLinear, news_test)
LinearPredict <- ifelse(LinearPredict > 0.43, 1,0)#Tested multiple cutoffs, this cutoff produces highest Kappa
LinearPredict <- as.factor(LinearPredict)

confusionMatrix(news_test$fake, LinearPredict)
```

## Logistic Regression
### Model Design
```{r}
FakeLog <- glm(fake ~ text_character_length + text_word_length + title_character_length + title_word_length, data = news_train )
summary(FakeLog)
#Significant factors: text_character_length, text_word_length, title_character_length, title_word_length
```
```{r}
FakeLog <- glm(fake ~ text_character_length + text_word_length + title_character_length + title_word_length + (text_character_length*text_word_length) + (title_character_length*title_word_length), data = news_train )
summary(FakeLog)
#Significant factors: text_character_length, text_word_length, title_character_length, title_word_length, title_character_length*title_word_length
```
```{r}
FakeLog <- glm(fake ~ text_character_length + text_word_length + title_character_length + title_word_length + (title_character_length*title_word_length) + I(text_character_length ^2) + I(title_character_length ^2) +I(text_word_length ^2) +I(title_word_length ^2), data = news_train)
summary(FakeLog)
#Significant factors: text_character_length, text_word_length, title_character_length, title_word_length, title_character_length*title_word_length, text_character_length^2, text_word_length^2, title_character_length^2, title_word_length^2
```
### Model Testing
```{r}
LogPredict <- predict(FakeLog, news_test)
LogPredict <- ifelse(LogPredict > 0.43, 1,0) #Tested multiple cutoffs, this cutoff produces highest Kappa
LogPredict <- as.factor(LogPredict)

confusionMatrix(news_test$fake, LogPredict)
```

